{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Prophet Customer Forecast\"\noutput:\n  word_document: default\n  pdf_document: default\n  html_document: default\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE)\n```\n\n## Introduction\n\nThis notebook will outline the steps to produce the prophet forecast, incorporating historical as well as future data for catalog circulation, marketing investment, and the J.Jill promotional calendar. The first step will be loading the required libraries to handle our data in R.\n\n\n```{r cars, , include=FALSE}\nlibrary(data.table)\nlibrary(zoo)\nlibrary(dplyr)\nlibrary(prophet)\n```\n\n## Loading the Data\n\nThere are 4 required files used to build this forecast. They are:\n\n1. Historical customer counts, monthly\n2. Historical and future investment numbers, monthly\n3. Historical and future catalog circulation, monthly\n4. Historical and future promotional calendar\n\nFirst we will investigate the customer data set.\n\n\n### Customer Data\n\n```{r }\n# sourced from alteryx workflow: Create Customer Data Set on latest masterXXk.yxdb file\n\nproph = read.csv('processed_customers.csv')\n```\n\n### Investment Data\n\n```{r }\n# sourced from Maria David, manually processed (no alteryx workflow)\n\ninv = read.csv('processed_investments.csv')\n```\n\n### Catalog Circulation Data\n\n```{r }\n# sourced from alteryx workflow: Prep Catalog History 20180613 on Jim's latest circulation calendar\ncirc = read.csv('processed_circ.csv')\n\n```\n\n\n### Promotional Calenendar Data\n\n```{r }\n# sourced from alteryx workflow: Prop Promo File 20180717 on Kaitlyn's latest promo calendar\npromos = read.csv('processed_promos.csv')\n```\n\n\nNow that we have all of the data prepped and ready for modeling, we can merge it into one larger file.\n\n### Merge training data\n```{r}\nregress = merge(proph, inv, by=c('FISCAL_YR', 'FISCAL_MO', 'Segment_Channel'), all.y=TRUE)\nregress$ds <- as.yearmon(paste(regress$FISCAL_YR, regress$FISCAL_MO, sep = \"-\"))\nsetnames(regress, 'monthly_customers', 'y')\n\nregress2 = merge(regress, promos, by = c('FISCAL_YR', 'FISCAL_MO', 'FISCAL_QTR', 'Segment_Channel'), all.y=TRUE)\nregress3 = merge(regress2, circ, by = c('FISCAL_YR', 'FISCAL_MO', 'FISCAL_QTR', 'Segment'), all.y=TRUE)\nregress3 = as.data.table(regress3)\n\ntrain = regress3[FISCAL_YR >= 2016]\n```\n\n\n\n### Define the forecasting Function\n\nThe primary function used to build this forecast is called `make_forecast` defined below. It takes two arguments, a data frame (df) as well as a threshold (threshold). The threshold is expected to be a year for which we want to forecast (i.e. 2019 or 2020). If you want to forecast for 2020, you should set the threshold to 2020, otherwise use 2019.\n\nThe forecast works by instantiating a prophet object (m) and setting a variety of parmeters relating to holidays, seasonality, and changepoints. Once the prophet object has been instantiated, a number of regressor variables can be added (any covariate column in the data frame argument can be incorporated as a regressor to the model.)\n\n```{r}\nmake_forecast <- function(df, threshold) {\n  #threshold = 2019\n  #df = regress2[Segment_Channel == 'React_Direct1']\n  df = as.data.table(df)\n  df = df[FISCAL_YR <= threshold]\n  m <- prophet(seasonality.mode = 'additive', holidays = holidays, holidays.prior.scale = .05, seasonality.prior.scale = 5, changepoint.prior.scale = .034, weekly.seasonality = FALSE, daily.seasonality = FALSE, yearly.seasonality = FALSE)\n  m <- add_regressor(m, name = 'circ_score')\n  #m <- add_regressor(m, name = 'investment')\n  #m <- add_regressor(m, name = 'peel_off_depth')\n  ##m <- add_regressor(m, name = 'post_card_depth')\n  #m <- add_regressor(m, name = 'free_ship_depth')\n  #m <- add_regressor(m, name = 'flash_sale_depth')\n  #m <- add_regressor(m, name = 'global_depth')\n  #m <- add_regressor(m, name = 'fp_entire_depth')\n  #m <- add_regressor(m, name = 'sp_entire_depth')\n  m <- add_seasonality(m, name='yearly', period=365.25, fourier.order=10, prior.scale = 0.05)\n  #m <- add_seasonality(m, name = 'quarterly', period = 365.25/4, fourier.order = 5, prior.scale = 15)\n  #m <- add_seasonality(m, name = 'monthly', period = 365.25/12, fourier.order = 3, prior.scale = 10)\n  m <- fit.prophet(m, df[FISCAL_YR <= (threshold - 1)])\n  future <- make_future_dataframe(m, periods = 12, freq = 'month')\n  future$circ_score = df$circ_score\n  #future$investment = df$investment  # FIXME this needs to be correctly specified\n  #future$peel_off_depth = df$peel_off_depth\n  ##future$post_card_depth = df$post_card_depth\n  #future$free_ship_depth = df$free_ship_depth\n  #future$flash_sale_depth = df$flash_sale_depth\n  #future$global_depth = df$global_depth\n  #future$fp_entire_depth = df$fp_entire_depth\n  #future$sp_entire_depth = df$sp_entire_depth\n  fcst <- predict(m, future)\n  prophet_plot_components(m, fcst)\n  return(fcst)\n}\n\n```\n\n\nNote that the function takes in a vector called `holidays.` We will need to define this vector to contain information on all of the J.Jill holidays. We do this manually by referencing the J.Jill fiscal calendar.\n\n```{r}\n\n# HOLIDAYS\nnew_years <- tibble(\n  holiday = 'new_years',\n  ds = as.Date(c('2017-12-01', '2018-11-01',\n                 '2019-12-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nwomens_day <- tibble(\n  holiday = 'womens_day',\n  ds = as.Date(c('2016-02-01', '2017-02-01', '2018-02-01',\n                 '2019-02-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\ngood_friday <- tibble(\n  holiday = 'good_friday',\n  ds = as.Date(c('2016-02-01', '2017-03-01', '2018-02-01',\n                 '2019-03-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\neaster <- tibble(\n  holiday = 'easter',\n  ds = as.Date(c('2016-02-01', '2017-03-01', '2018-02-01',\n                 '2019-03-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nmothers_day <- tibble(\n  holiday = 'mothers_day',\n  ds = as.Date(c('2016-04-01', '2017-04-01', '2018-04-01',\n                 '2019-04-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nmemorial <- tibble(\n  # on average +17k customers\n  holiday = 'memorial',\n  ds = as.Date(c('2016-05-01', '2017-05-01', '2018-04-01',\n                 '2019-04-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nindependence <- tibble(\n  # on average +5k customers\n  holiday = 'independence',\n  ds = as.Date(c('2016-06-01', '2017-06-01', '2018-05-01',\n                 '2019-05-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nlabor <- tibble(\n  # on average +20k customers\n  holiday = 'labor',\n  ds = as.Date(c('2016-08-01', '2017-08-01', '2018-08-01',\n                 '2019-08-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nthanksgiv <- tibble(\n  holiday = 'thanksgiv',\n  ds = as.Date(c('2016-10-01', '2017-10-01', '2018-10-01',\n                 '2019-10-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nblack_fri <- tibble(\n  holiday = 'black_fri',\n  ds = as.Date(c('2016-10-01', '2017-10-01', '2018-10-01',\n                 '2019-10-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\ncyber_monday <- tibble(\n  holiday = 'cyber_monday',\n  ds = as.Date(c('2016-11-01', '2017-11-01', '2018-10-01',\n                 '2019-11-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nchrist_eve <- tibble(\n  holiday = 'christ_eve',\n  ds = as.Date(c('2016-11-01', '2017-11-01', '2018-11-01',\n                 '2019-11-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nchrist <- tibble(\n  holiday = 'christ',\n  ds = as.Date(c('2016-11-01', '2017-11-01', '2018-11-01',\n                 '2019-11-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\nnye <- tibble(\n  holiday = 'nye',\n  ds = as.Date(c('2016-11-01', '2017-12-01', '2018-11-01',\n                 '2019-11-01')),\n  lower_window = 0,\n  upper_window = 1\n)\n\n\n\n\n\n\nholidays <- bind_rows(nye, christ, cyber_monday, christ_eve,black_fri, thanksgiv, labor, independence, memorial, mothers_day, easter, good_friday, womens_day, new_years)\n\n\n```\n\n\n\n\n\nNow that our function is defined and our holidays are coded, the next step is to produce a forecast for each of the segment channels in question. We will use R's built in `dplyr` package to do this programmatically.\n\n### Call our function for each segment channel in our dataframe\n\nThis block of code will run our make forecast function for 2019 9 times (note that we are grouping by Segment Channel). This means the forecast will run once for each segment channel that exists in our data frame.\n\n```{r}\nfcst = train %>%  \n  group_by(Segment_Channel) %>%\n  do(make_forecast(., 2019)) %>% \n  dplyr::select(ds, Segment_Channel, yhat)\n```\n\nNow we have a forecast at the monthly level. The next step will be to calculate how this monthly forecast will translate to quarterly and yearly totals. We will define a function `calc_year_end` to do this for us. This function will use two files, `monthly_pacing` taken from `percentages.txt` and `quarter_totals` taken from `quarter_totals.txt.` Both of these files were sourced from alteryx workflow: `percentages.yxmd`\n\n\n```{r}\nmonthly_pacing = fread(\"percentages.txt\", sep= '|')\nsetnames(monthly_pacing, 'Fiscal_Mo', 'FISCAL_MO')\n\n\n\nquarterly_pacing = fread(\"quarter_totals.txt\", sep= '|')\nquarterly_pacing[, quarter := ifelse(FISCAL_MO <= 3, 1, ifelse(FISCAL_MO <= 6, 2, ifelse(FISCAL_MO <= 9, 3, 4)))]\nquarterly_pacing[, quarter_sum := sum(cust_month), by=c(\"quarter\", \"Customer_Type\")]\nquarterly_pacing[, table := cust_quarter/quarter_sum]\nquarter_table = unique(quarterly_pacing[, c(\"Customer_Type\", \"quarter\", \"table\", \"quarter_sum\")])\nsetnames(quarter_table, \"Customer_Type\", \"Segment_Channel\")\n\n\ncalc_year_end <- function(cast_dat, year, hist) {\n  et = as.data.table(cast_dat)\n  et[, FISCAL_MO := month(ds)]\n  et[, quarter := ifelse(FISCAL_MO %in% c(1,2,3), 1, ifelse(FISCAL_MO %in% c(4,5,6), 2, ifelse(FISCAL_MO %in% c(7,8,9), 3,4)))]\n  et[, day := format(as.Date(ds,format=\"%Y-%m-%d\"), \"%d\")]\n  et[, FISCAL_YR := year(ds)]\n  et = et[ day == '01']\n  setnames(et, 'yhat', 'Used_Forecast')\n  \n  \n  \n  #wrap up\n  df2 = hist[, c('Segment_Channel', 'FISCAL_YR', 'FISCAL_MO', 'y')]\n  et2 = merge(et, df2, by=c('Segment_Channel', 'FISCAL_MO', 'FISCAL_YR'), all.x=TRUE)\n  et2[, Used_Forecasta := ifelse(is.na(y), Used_Forecast, y)]\n\n  \n  year_agg = merge(et2, monthly_pacing, by = c(\"Segment_Channel\", \"FISCAL_MO\"))\n  year_agg = merge(year_agg, quarter_table, by = c(\"quarter\", \"Segment_Channel\"))\n  year_agg[, Year_Number2 := Used_Forecast * percent]\n  year_agg[, Year_Number2a := Used_Forecasta * percent]\n  year_agg[, qnum := table*Used_Forecast]\n  year_agg[, qnuma := table * Used_Forecasta]\n\n  \n  return(year_agg)\n}\n\n\n```\n\n### Examine results of forecasting run\n```{r}\nfinal_fcst = calc_year_end(fcst, 2019, regress3) \nfinal_fcst = final_fcst[FISCAL_YR == 2019]\n```\n\n\n\n```{r}\n#estimates = c(1, 0.544586951, 0.366562835, 0.337894522)\n#q_s = final_fcst %>% group_by(quarter, Segment_Channel) %>% summarize(sum(qnuma))\n#q_s\n#sum(q_s*estimates) #1921\n```\n\nOnce we are happy with the output of our forecast, the final step is to write it to a csv file. The data from this csv file should be pasted into the `Prophet Forecast Data` tab of august_2020_v2 excel workbook. The data and forecast will update automatically after copying and pasting.\n\n### Write out forecast to csv file\n\n```{r}\nwrite.csv(final_fcst, '~/Desktop/prophet_aug.csv')\n```\n\n\n\n\n\n",
    "created" : 1566316697470.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2523537035",
    "id" : "1BF8B3D",
    "lastKnownWriteTime" : 1566338085,
    "last_content_update" : 1566338085,
    "path" : "~/Desktop/janes_functions/prophet_package/prophet_writeup.Rmd",
    "project_path" : "prophet_writeup.Rmd",
    "properties" : {
        "source_window_id" : "wiacl5849loc6"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}